## Deep Neutral Network ##
### xor ###
	#!/usr/bin/env python
	# -*- coding:utf-8 -*-
	
	import tensorflow as tf
	import numpy as np
	
	tf.set_random_seed(777)  # for reproducibility
	learning_rate = 0.1
	
	x_data = [[0, 0],
	          [0, 1],
	          [1, 0],
	          [1, 1]]
	y_data = [[0],
	          [1],
	          [1],
	          [0]]
	x_data = np.array(x_data, dtype=np.float32)
	y_data = np.array(y_data, dtype=np.float32)
	
	X = tf.placeholder(tf.float32, [None, 2])
	Y = tf.placeholder(tf.float32, [None, 1])
	
	W = tf.Variable(tf.random_normal([2, 1]), name='weight')
	b = tf.Variable(tf.random_normal([1]), name='bias')
	
	# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))
	hypothesis = tf.sigmoid(tf.matmul(X, W) + b)
	
	# cost/loss function
	cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *
	                       tf.log(1 - hypothesis))
	
	train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(
	    cost)
	
	# Accuracy computation
	# True if hypothesis>0.5 else False
	predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)
	accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))
	
	# Launch graph
	with tf.Session() as sess:
	    # Initialize TensorFlow variables
	    sess.run(tf.global_variables_initializer())
	
	    for step in range(10001):
	        sess.run(train, feed_dict={X: x_data, Y: y_data})
	        if step % 100 == 0:
	            print(step, sess.run(cost, feed_dict={
	                X: x_data, Y: y_data}), sess.run(W))
	
	    # Accuracy report
	    h, c, a = sess.run([hypothesis, predicted, accuracy],
	                       feed_dict={X: x_data, Y: y_data})
	    print("\nHypothesis: ", h, "\nCorrect: ", c, "\nAccuracy: ", a)
	
	“”“
		0 0.87597954 [[0.7863567]
		 [0.6628261]]
		100 0.6957122 [[0.23303682]
		 [0.16537338]]
		...

		9900 0.6931472 [[1.3280558e-07]
		 [1.3386332e-07]]
		10000 0.6931472 [[1.3280558e-07]
		 [1.3386332e-07]]
		
		Hypothesis:  [[0.5]
		 [0.5]
		 [0.5]
		 [0.5]] 
		Correct:  [[0.]
		 [0.]
		 [0.]
		 [0.]] 
		Accuracy:  0.5
	“”“
[参阅xor](https://github.com/hunkim/DeepLearningZeroToAll/blob/master/lab-09-1-xor.py)

### NN for xor ###
	#!/usr/bin/env python
	# -*- coding:utf-8 -*-
	
	import tensorflow as tf
	import numpy as np
	
	tf.set_random_seed(777)  # for reproducibility
	learning_rate = 0.1
	
	x_data = [[0, 0],
	          [0, 1],
	          [1, 0],
	          [1, 1]]
	y_data = [[0],
	          [1],
	          [1],
	          [0]]
	x_data = np.array(x_data, dtype=np.float32)
	y_data = np.array(y_data, dtype=np.float32)
	
	X = tf.placeholder(tf.float32, [None, 2])
	Y = tf.placeholder(tf.float32, [None, 1])
	
	W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')
	b1 = tf.Variable(tf.random_normal([2]), name='bias1')
	layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)
	
	W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')
	b2 = tf.Variable(tf.random_normal([1]), name='bias2')
	hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)
	
	# cost/loss function
	cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *
	                       tf.log(1 - hypothesis))
	
	train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(
	    cost)
	
	# Accuracy computation
	# True if hypothesis>0.5 else False
	predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)
	accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))
	
	# Launch graph
	with tf.Session() as sess:
	    # Initialize TensorFlow variables
	    sess.run(tf.global_variables_initializer())
	
	    for step in range(10001):
	        sess.run(train, feed_dict={X: x_data, Y: y_data})
	        if step % 100 == 0:
	            print(step, sess.run(cost, feed_dict={
	                X: x_data, Y: y_data}), sess.run([W1, W2]))
	
	    # Accuracy report
	    h, c, a = sess.run([hypothesis, predicted, accuracy],
	                       feed_dict={X: x_data, Y: y_data})
	    print("\nHypothesis: ", h, "\nCorrect: ", c, "\nAccuracy: ", a)

	"""
		0 0.7539022 [array([[ 0.7988674 ,  0.6801188 ],
		       [-1.2198634 , -0.30361032]], dtype=float32), array([[ 1.3752297 ],
		       [-0.78823847]], dtype=float32)]
		100 0.69584423 [array([[ 0.671669  ,  0.71368533],
		       [-1.2917174 , -0.24467792]], dtype=float32), array([[ 1.1212678 ],
		       [-0.90971726]], dtype=float32)]
		...

		9900 0.014045564 [array([[ 6.2560105,  6.114064 ],
	       [-6.37964  , -5.808116 ]], dtype=float32), array([[10.073595],
	       [-9.571595]], dtype=float32)]
		10000 0.013844791 [array([[ 6.263471 ,  6.1245112],
		       [-6.3876433, -5.818806 ]], dtype=float32), array([[10.100041],
		       [-9.598662]], dtype=float32)]

		Hypothesis:  [[0.01338218]
		 [0.98166394]
		 [0.98809403]
		 [0.01135799]] 
		Correct:  [[0.]
		 [1.]
		 [1.]
		 [0.]] 
		Accuracy:  1.0
	"""
[参阅xor-nn](https://github.com/hunkim/DeepLearningZeroToAll/blob/master/lab-09-2-xor-nn.py)

### xor-nn-wide-deep ###
	#!/usr/bin/env python
	# -*- coding:utf-8 -*-
	
	import tensorflow as tf
	import numpy as np
	
	tf.set_random_seed(777)  # for reproducibility
	learning_rate = 0.1
	
	x_data = [[0, 0],
	          [0, 1],
	          [1, 0],
	          [1, 1]]
	y_data = [[0],
	          [1],
	          [1],
	          [0]]
	x_data = np.array(x_data, dtype=np.float32)
	y_data = np.array(y_data, dtype=np.float32)
	
	X = tf.placeholder(tf.float32, [None, 2])
	Y = tf.placeholder(tf.float32, [None, 1])
	
	W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')
	b1 = tf.Variable(tf.random_normal([10]), name='bias1')
	layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)
	
	W2 = tf.Variable(tf.random_normal([10, 10]), name='weight2')
	b2 = tf.Variable(tf.random_normal([10]), name='bias2')
	layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)
	
	W3 = tf.Variable(tf.random_normal([10, 10]), name='weight3')
	b3 = tf.Variable(tf.random_normal([10]), name='bias3')
	layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)
	
	W4 = tf.Variable(tf.random_normal([10, 1]), name='weight4')
	b4 = tf.Variable(tf.random_normal([1]), name='bias4')
	hypothesis = tf.sigmoid(tf.matmul(layer3, W4) + b4)
	
	# cost/loss function
	cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *
	                       tf.log(1 - hypothesis))
	
	train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(
	    cost)
	
	# Accuracy computation
	# True if hypothesis>0.5 else False
	predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)
	accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))
	
	# Launch graph
	with tf.Session() as sess:
	    # Initialize TensorFlow variables
	    sess.run(tf.global_variables_initializer())
	
	    for step in range(10001):
	        sess.run(train, feed_dict={X: x_data, Y: y_data})
	        if step % 100 == 0:
	            print(step, sess.run(cost, feed_dict={
	                X: x_data, Y: y_data}), sess.run([W1, W2]))
	
	    # Accuracy report
	    h, c, a = sess.run([hypothesis, predicted, accuracy],
	                       feed_dict={X: x_data, Y: y_data})
	    print("\nHypothesis: ", h, "\nCorrect: ", c, "\nAccuracy: ", a)

	"""
		...

		10000 0.0011807142 [array([[ 2.218368  ,  1.2735564 , -2.090514  , -0.61827236, -0.66737646,
	         3.3285062 ,  3.9355118 , -1.7987194 , -2.540843  ,  1.1298105 ],
	       [ 0.8230299 ,  2.4202335 , -1.2729847 ,  3.6523008 ,  0.4531163 ,
	         3.012509  , -2.624716  , -1.8317369 ,  1.1282953 , -1.0262976 ]],
	      dtype=float32), array([[ 0.54422283, -1.2369914 , -1.0413734 , -1.1066569 , -0.19528544,
	         1.6709634 , -0.57744795, -0.57992065,  2.844603  , -2.8085065 ],
	       [ 1.4555976 , -0.7099258 , -0.76188064, -1.5103563 ,  0.8742827 ,
	        -0.3065544 ,  0.6780464 ,  0.608948  , -1.151392  , -2.251602  ],
	       [ 2.2474587 ,  1.1162733 ,  2.1688151 ,  1.2717164 , -1.9511781 ,
	         1.0597996 ,  0.8263019 ,  1.8826894 , -0.59315807,  0.41328436],
	       [ 3.5166862 ,  1.1133729 ,  0.22091061, -2.2782514 , -1.3083824 ,
	         1.11306   , -0.244322  , -1.0237467 ,  0.28201333, -1.6689649 ],
	       [-0.13293734,  0.02770616, -0.17223132,  0.44822502, -0.26150122,
	         0.42182478, -0.32187465, -0.9666031 ,  0.02885718,  0.9812633 ],
	       [-3.3994207 ,  2.244699  , -1.8380874 ,  0.9052288 , -0.0902309 ,
	         1.7158539 , -0.6028561 ,  0.33625057,  0.234646  , -0.6239138 ],
	       [ 1.9015687 , -3.994602  ,  0.06738015, -0.6643163 , -0.638776  ,
	         1.6363573 , -1.7501605 ,  0.92682606, -1.3820325 ,  0.4724037 ],
	       [ 1.356658  , -1.4853196 ,  1.0827296 ,  1.41166   , -0.06309295,
	         1.7158324 ,  0.58975583, -0.6710832 ,  1.4941695 ,  1.6895472 ],
	       [-0.8604476 ,  0.83614385, -0.5084675 ,  2.510769  ,  1.8767374 ,
	        -0.25638062,  0.47463647, -3.4265053 , -0.8359773 ,  1.7084935 ],
	       [-1.0343286 , -1.7003134 , -0.2295237 ,  2.0122669 ,  0.33882123,
	         0.796408  ,  0.07112981, -1.5737023 , -1.1570723 , -1.7104335 ]],
	      dtype=float32)]

		Hypothesis:  [[7.8051217e-04]
		 [9.9923813e-01]
		 [9.9837923e-01]
		 [1.5565879e-03]] 
		Correct:  [[0.]
		 [1.]
		 [1.]
		 [0.]] 
		Accuracy:  1.0
	"""
[参阅xor-nn-wide-deep](https://github.com/hunkim/DeepLearningZeroToAll/blob/master/lab-09-3-xor-nn-wide-deep.py)
